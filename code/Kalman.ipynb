{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:14:43.777679Z",
     "start_time": "2024-12-06T05:14:43.734619Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pickle\n",
    "from pykalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "# def add_gaussian_noise_to_signal(signal, mean=0, std=1):\n",
    "#     noisy_signal = signal.copy()\n",
    "#     noisy_signal['depth'] = noisy_signal['depth'] + np.random.normal(mean, std, len(noisy_signal['depth']))\n",
    "#     return noisy_signal\n",
    "# \n",
    "# df['noisy_signal'] = df['decrease'].apply(lambda x: add_gaussian_noise_to_signal(x, mean=0, std=0.1))  # Adjust `std` as needed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:14:43.814369Z",
     "start_time": "2024-12-06T05:14:43.736344Z"
    }
   },
   "id": "8f82f40ccc7a8c43"
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "data": {
      "text/plain": "             deployment_id  label  inflection_t  \\\nuuid                                              \n1690089  daily_happy_satyr  flood          6961   \n2578925  daily_happy_satyr  flood          7062   \n5301386  daily_happy_satyr  flood          5303   \n2808962  daily_happy_satyr  flood          4789   \n9041605  daily_happy_satyr  flood          6188   \n\n                                                    signal  \\\nuuid                                                         \n1690089  {'time': [0, 567, 1009, 1639, 1765, 2080, 2395...   \n2578925  {'time': [0, 1889, 1952, 2960, 4914, 4921, 674...   \n5301386  {'time': [0, 1323, 1898, 1906, 2409, 2535, 278...   \n2808962  {'time': [126, 441, 503, 566, 882, 1008, 1071,...   \n9041605  {'time': [0, 379, 1449, 1575, 1890, 2394, 2709...   \n\n                                             signal_padded  \\\nuuid                                                         \n1690089  {'time': [0, 60, 120, 180, 240, 300, 867, 1309...   \n2578925  {'time': [0, 60, 120, 180, 240, 300, 2189, 225...   \n5301386  {'time': [0, 60, 120, 180, 240, 300, 1623, 219...   \n2808962  {'time': [0, 60, 120, 180, 240, 300, 615, 677,...   \n9041605  {'time': [0, 60, 120, 180, 240, 300, 679, 1749...   \n\n                                                signal_sim  \\\nuuid                                                         \n1690089  {'time': [0, 567, 1009, 1639, 1765, 2080, 2395...   \n2578925  {'time': [0, 1889, 1952, 2960, 4914, 4921, 674...   \n5301386  {'time': [0, 1323, 1898, 1906, 2409, 2535, 278...   \n2808962  {'time': [126, 441, 503, 566, 882, 1008, 1071,...   \n9041605  {'time': [0, 379, 1449, 1575, 1890, 2394, 2709...   \n\n                                         signal_sim_padded  \nuuid                                                        \n1690089  {'time': [0, 60, 120, 180, 240, 300, 867, 1309...  \n2578925  {'time': [0, 60, 120, 180, 240, 300, 2189, 225...  \n5301386  {'time': [0, 60, 120, 180, 240, 300, 1623, 219...  \n2808962  {'time': [0, 60, 120, 180, 240, 300, 615, 677,...  \n9041605  {'time': [0, 60, 120, 180, 240, 300, 679, 1749...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>deployment_id</th>\n      <th>label</th>\n      <th>inflection_t</th>\n      <th>signal</th>\n      <th>signal_padded</th>\n      <th>signal_sim</th>\n      <th>signal_sim_padded</th>\n    </tr>\n    <tr>\n      <th>uuid</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1690089</th>\n      <td>daily_happy_satyr</td>\n      <td>flood</td>\n      <td>6961</td>\n      <td>{'time': [0, 567, 1009, 1639, 1765, 2080, 2395...</td>\n      <td>{'time': [0, 60, 120, 180, 240, 300, 867, 1309...</td>\n      <td>{'time': [0, 567, 1009, 1639, 1765, 2080, 2395...</td>\n      <td>{'time': [0, 60, 120, 180, 240, 300, 867, 1309...</td>\n    </tr>\n    <tr>\n      <th>2578925</th>\n      <td>daily_happy_satyr</td>\n      <td>flood</td>\n      <td>7062</td>\n      <td>{'time': [0, 1889, 1952, 2960, 4914, 4921, 674...</td>\n      <td>{'time': [0, 60, 120, 180, 240, 300, 2189, 225...</td>\n      <td>{'time': [0, 1889, 1952, 2960, 4914, 4921, 674...</td>\n      <td>{'time': [0, 60, 120, 180, 240, 300, 2189, 225...</td>\n    </tr>\n    <tr>\n      <th>5301386</th>\n      <td>daily_happy_satyr</td>\n      <td>flood</td>\n      <td>5303</td>\n      <td>{'time': [0, 1323, 1898, 1906, 2409, 2535, 278...</td>\n      <td>{'time': [0, 60, 120, 180, 240, 300, 1623, 219...</td>\n      <td>{'time': [0, 1323, 1898, 1906, 2409, 2535, 278...</td>\n      <td>{'time': [0, 60, 120, 180, 240, 300, 1623, 219...</td>\n    </tr>\n    <tr>\n      <th>2808962</th>\n      <td>daily_happy_satyr</td>\n      <td>flood</td>\n      <td>4789</td>\n      <td>{'time': [126, 441, 503, 566, 882, 1008, 1071,...</td>\n      <td>{'time': [0, 60, 120, 180, 240, 300, 615, 677,...</td>\n      <td>{'time': [126, 441, 503, 566, 882, 1008, 1071,...</td>\n      <td>{'time': [0, 60, 120, 180, 240, 300, 615, 677,...</td>\n    </tr>\n    <tr>\n      <th>9041605</th>\n      <td>daily_happy_satyr</td>\n      <td>flood</td>\n      <td>6188</td>\n      <td>{'time': [0, 379, 1449, 1575, 1890, 2394, 2709...</td>\n      <td>{'time': [0, 60, 120, 180, 240, 300, 679, 1749...</td>\n      <td>{'time': [0, 379, 1449, 1575, 1890, 2394, 2709...</td>\n      <td>{'time': [0, 60, 120, 180, 240, 300, 679, 1749...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"flood_df\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:14:43.819236Z",
     "start_time": "2024-12-06T05:14:43.738545Z"
    }
   },
   "id": "4cac7cb24ac78335"
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time  depth\n",
      "0       0    0.0\n",
      "1      60    0.0\n",
      "2     120    0.0\n",
      "3     180    0.0\n",
      "4     240    0.0\n",
      "5     300    4.0\n",
      "6     867   18.0\n",
      "7    1309   25.0\n",
      "8    1939   35.0\n",
      "9    2065   37.0\n",
      "10   2380   50.0\n",
      "11   2695   64.0\n",
      "12   2947   79.0\n",
      "13   3010   82.0\n",
      "14   3136   90.0\n",
      "15   3387  110.0\n",
      "16   3766  139.0\n",
      "17   4018  160.0\n",
      "18   4080  164.0\n",
      "19   4332  181.0\n",
      "20   5215  237.0\n",
      "21   5781  266.0\n",
      "22   6033  274.0\n",
      "23   6229  283.0\n",
      "24   6489  292.0\n",
      "25   6560  296.0\n",
      "26   6568  296.0\n",
      "27   6694  298.0\n",
      "28   6757  298.0\n",
      "29   6820  300.0\n",
      "30   7198  307.0\n",
      "31   7261  308.0\n",
      "32   7386  310.0\n",
      "33   7575  307.0\n",
      "34   7638  302.0\n",
      "35   8142  297.0\n",
      "36   8269  292.0\n",
      "37   9088  268.0\n",
      "38   9151  266.0\n",
      "39   9403  260.0\n",
      "40  10033  240.0\n",
      "41  10536  220.0\n",
      "42  10915  204.0\n",
      "43  11230  189.0\n",
      "44  11734  162.0\n",
      "45  12238  131.0\n",
      "46  12868   85.0\n",
      "47  12993   74.0\n",
      "48  13182   59.0\n",
      "49  13497   34.0\n",
      "50  13560   24.0\n",
      "51  13812    2.0\n",
      "52  13872    0.0\n",
      "53  13932    0.0\n",
      "54  13992    0.0\n",
      "55  14052    0.0\n",
      "56  14112    0.0\n"
     ]
    }
   ],
   "source": [
    "def preprocess_signal(signal):\n",
    "    time = signal['time']\n",
    "    depth = signal['depth']\n",
    "    return pd.DataFrame({'time': time, 'depth': depth}).sort_values(by='time')\n",
    "\n",
    "df['processed_signal'] = df['signal_padded'].apply(preprocess_signal)\n",
    "print(df['processed_signal'].iloc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:14:43.914925Z",
     "start_time": "2024-12-06T05:14:43.808079Z"
    }
   },
   "id": "983b9681d5d65f2c"
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "def vectorized_kalman_filter_3d(signal):\n",
    "    observations = signal['depth'].values\n",
    "    times = signal['time'].values\n",
    "    time_diffs = np.diff(times, prepend=times[0])  # Compute time gaps with 0 for the first element\n",
    "\n",
    "    # Initialize state and covariance matrices\n",
    "    n_observations = len(observations)\n",
    "    state_dim = 3  # [depth, velocity, acceleration]\n",
    "    filtered_means = np.zeros((n_observations, state_dim))\n",
    "    smoothed_means = np.zeros((n_observations, state_dim))\n",
    "    covariances = np.zeros((n_observations, state_dim, state_dim))\n",
    "\n",
    "    # Initial state and covariance\n",
    "    state_mean = np.array([observations[0], 0, 0])  # Initial [depth, velocity, acceleration]\n",
    "    state_covariance = np.eye(state_dim) * 1  # Initial uncertainty\n",
    "    observation_matrix = np.array([[1, 0, 0]])  # Observation model\n",
    "    observation_covariance = np.array([[1]])  # Observation noise\n",
    "    process_noise_base = np.array([[6, 0.05, 0.0], [6, 0.1, 0.0], [0.0, 0.0, 0.0]]) / 10\n",
    "\n",
    "    epsilon = 1e-6  # Small value for regularization\n",
    "\n",
    "    # Filtering\n",
    "    for t in range(n_observations):\n",
    "        if t > 0:\n",
    "            delta_t = time_diffs[t - 1]\n",
    "            transition_matrix = np.array([\n",
    "                [1, delta_t, 0.5 * delta_t**2],\n",
    "                [0, 1, delta_t],\n",
    "                [0, 0, 1]\n",
    "            ])\n",
    "            process_noise = process_noise_base * delta_t\n",
    "\n",
    "            # Predict step\n",
    "            predicted_state_mean = np.dot(transition_matrix, state_mean)\n",
    "            predicted_state_cov = (\n",
    "                np.dot(transition_matrix, np.dot(state_covariance, transition_matrix.T)) + process_noise\n",
    "            )\n",
    "\n",
    "            # Update step\n",
    "            innovation = observations[t] - np.dot(observation_matrix, predicted_state_mean)\n",
    "            innovation_cov = (\n",
    "                np.dot(observation_matrix, np.dot(predicted_state_cov, observation_matrix.T))\n",
    "                + observation_covariance\n",
    "            )\n",
    "            kalman_gain = np.dot(\n",
    "                predicted_state_cov,\n",
    "                np.dot(observation_matrix.T, np.linalg.inv(innovation_cov + epsilon * np.eye(innovation_cov.shape[0])))\n",
    "            )\n",
    "            state_mean = predicted_state_mean + np.dot(kalman_gain, innovation)\n",
    "            state_covariance = predicted_state_cov - np.dot(\n",
    "                kalman_gain, np.dot(observation_matrix, predicted_state_cov)\n",
    "            )\n",
    "\n",
    "        # Store filtered results\n",
    "        filtered_means[t] = state_mean\n",
    "        covariances[t] = state_covariance\n",
    "\n",
    "    # Smoothing\n",
    "    smoothed_means[-1] = filtered_means[-1]\n",
    "    smoothed_covariance = covariances[-1]\n",
    "    for t in range(n_observations - 2, -1, -1):\n",
    "        delta_t = time_diffs[t]\n",
    "        transition_matrix = np.array([\n",
    "            [1, delta_t, 0.5 * delta_t**2],\n",
    "            [0, 1, delta_t],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "\n",
    "        # RTS smoother gain\n",
    "        predicted_covariance = (\n",
    "            np.dot(transition_matrix, np.dot(covariances[t], transition_matrix.T)) + process_noise_base * delta_t\n",
    "        )\n",
    "        predicted_covariance += epsilon * np.eye(predicted_covariance.shape[0])  # Regularization\n",
    "        smoother_gain = np.dot(\n",
    "            covariances[t],\n",
    "            np.dot(transition_matrix.T, np.linalg.pinv(predicted_covariance))  # Use pseudo-inverse\n",
    "        )\n",
    "\n",
    "        # Update smoothed state\n",
    "        smoothed_means[t] = (\n",
    "            filtered_means[t]\n",
    "            + np.dot(smoother_gain, (smoothed_means[t + 1] - np.dot(transition_matrix, filtered_means[t])))\n",
    "        )\n",
    "\n",
    "    # Add filtered and smoothed results to the signal DataFrame\n",
    "    signal['kalman_depth'] = filtered_means[:, 0]\n",
    "    signal['smoothed_depth'] = smoothed_means[:, 0]\n",
    "    signal['velocity'] = filtered_means[:, 1]\n",
    "    signal['acceleration'] = filtered_means[:, 2]\n",
    "    return signal\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:14:43.940240Z",
     "start_time": "2024-12-06T05:14:43.865261Z"
    }
   },
   "id": "601137d3368486bb"
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "import numpy as np\n",
    "\n",
    "def em_kalman_global(processed_signals, max_iterations=50, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Perform EM to estimate global parameters across multiple time-series signals.\n",
    "    \n",
    "    Args:\n",
    "        processed_signals: A Series where each element is a time-series DataFrame (e.g., df['processed_signal']).\n",
    "        max_iterations: Maximum number of EM iterations.\n",
    "        tol: Convergence tolerance.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of global parameters:\n",
    "        - transition_matrix: Estimated state transition matrix.\n",
    "        - process_noise_base: Estimated process noise covariance.\n",
    "        - observation_covariance: Estimated observation noise covariance.\n",
    "    \"\"\"\n",
    "    # Normalize the signals without modifying the originals\n",
    "    signals_normalized = []\n",
    "    signal_scales = []\n",
    "    for signal in processed_signals:\n",
    "        signal_copy = signal.copy()  # Work on a copy to preserve original data\n",
    "        scale = np.std(signal_copy['depth'].values)\n",
    "        if scale == 0:\n",
    "            scale = 1  # Avoid division by zero for constant signals\n",
    "        signal_copy['depth'] /= scale  # Normalize depth\n",
    "        signals_normalized.append(signal_copy)\n",
    "        signal_scales.append(scale)\n",
    "\n",
    "    # Initial global parameters\n",
    "    state_dim = 3\n",
    "    observation_dim = 1\n",
    "    transition_matrix = np.array([\n",
    "        [1, 1, 0.5],\n",
    "        [0, 1, 1],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    observation_matrix = np.array([[1, 0, 0]])\n",
    "    process_noise_base = np.eye(state_dim) * 0.1\n",
    "    observation_covariance = np.eye(observation_dim) * 0.1\n",
    "    epsilon = 1e-6  # Small value for regularization\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Initialize accumulators for sufficient statistics\n",
    "        total_transition_numerator = np.zeros_like(transition_matrix)\n",
    "        total_transition_denominator = np.zeros((state_dim, state_dim))\n",
    "        total_process_noise = np.zeros_like(process_noise_base)\n",
    "        total_observation_covariance = np.zeros_like(observation_covariance)\n",
    "\n",
    "        for signal, scale in zip(signals_normalized, signal_scales):\n",
    "            # Extract observations\n",
    "            observations = signal['depth'].values\n",
    "            n_observations = len(observations)\n",
    "\n",
    "            # Initialize Kalman Filter\n",
    "            kf = KalmanFilter(\n",
    "                transition_matrices=transition_matrix,\n",
    "                observation_matrices=observation_matrix,\n",
    "                transition_covariance=process_noise_base,\n",
    "                observation_covariance=observation_covariance,\n",
    "                initial_state_mean=np.zeros(state_dim),\n",
    "                initial_state_covariance=np.eye(state_dim)\n",
    "            )\n",
    "\n",
    "            # Apply filtering and smoothing\n",
    "            smoothed_state_means, smoothed_state_covariances = kf.smooth(observations)\n",
    "\n",
    "            # Accumulate statistics for M-step\n",
    "            for t in range(1, n_observations):\n",
    "                residual = smoothed_state_means[t] - np.dot(transition_matrix, smoothed_state_means[t - 1])\n",
    "                total_transition_numerator += np.outer(smoothed_state_means[t], smoothed_state_means[t - 1])\n",
    "                total_transition_denominator += np.outer(smoothed_state_means[t - 1], smoothed_state_means[t - 1])\n",
    "                total_process_noise += np.outer(residual, residual)\n",
    "\n",
    "            for t in range(n_observations):\n",
    "                innovation = observations[t] - np.dot(observation_matrix, smoothed_state_means[t])\n",
    "                total_observation_covariance += np.outer(innovation, innovation)\n",
    "\n",
    "        # M-Step: Update global parameters\n",
    "        transition_matrix = np.dot(total_transition_numerator, np.linalg.pinv(total_transition_denominator))\n",
    "        process_noise_base = total_process_noise / (len(processed_signals) * (n_observations - 1))\n",
    "        observation_covariance = total_observation_covariance / (len(processed_signals) * n_observations)\n",
    "\n",
    "        # Regularize covariance updates\n",
    "        observation_covariance += epsilon * np.eye(observation_dim)\n",
    "        observation_covariance = np.clip(observation_covariance, 0, 10)  # Cap values for stability\n",
    "\n",
    "        # Convergence check\n",
    "        if np.max(np.abs(total_transition_numerator - transition_matrix)) < tol:\n",
    "            break\n",
    "\n",
    "\n",
    "    return transition_matrix, process_noise_base, observation_covariance\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:14:43.940384Z",
     "start_time": "2024-12-06T05:14:43.871370Z"
    }
   },
   "id": "f6e6757627e61c49"
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [],
   "source": [
    "transition_matrix, process_noise_base, observation_covariance = em_kalman_global(df['processed_signal'])\n",
    "global_params = {'transition_matrix': transition_matrix, 'process_noise_base':process_noise_base, 'observation_covariance':observation_covariance}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:23:18.418889Z",
     "start_time": "2024-12-06T05:14:43.875442Z"
    }
   },
   "id": "ae73112a2bec3a41"
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'transition_matrix': array([[ 9.99018274e-01,  9.48795654e-01, -1.43292859e-01],\n",
      "       [ 1.09130675e-03,  9.89511485e-01,  1.83790053e+00],\n",
      "       [-1.82489161e-05, -3.37200636e-03,  9.69293568e-01]]), 'process_noise_base': array([[ 1.97062489e-17,  3.51189104e-21, -8.38193436e-21],\n",
      "       [ 3.51189104e-21,  1.11570011e-23,  3.71038592e-24],\n",
      "       [-8.38193436e-21,  3.71038592e-24,  6.67319294e-24]]), 'observation_covariance': array([[7.07154092]])}\n"
     ]
    }
   ],
   "source": [
    "print(global_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:23:18.506831Z",
     "start_time": "2024-12-06T05:23:18.399258Z"
    }
   },
   "id": "2facf38e5f4b63ab"
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [],
   "source": [
    "with open('global_params.pkl', 'wb') as file:\n",
    "    pickle.dump(global_params, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:23:18.507319Z",
     "start_time": "2024-12-06T05:23:18.411793Z"
    }
   },
   "id": "5ae89f1cb40c53f"
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [],
   "source": [
    "def apply_kalman_filter(processed_signals, transition_matrix, process_noise_base, observation_covariance):\n",
    "    \"\"\"\n",
    "    Apply the Kalman Filter and Smoother using global parameters to all processed signals.\n",
    "\n",
    "    Args:\n",
    "        processed_signals: A Series where each element is a time-series DataFrame (e.g., df['processed_signal']).\n",
    "        transition_matrix: The global state transition matrix estimated from EM.\n",
    "        process_noise_base: The global process noise covariance estimated from EM.\n",
    "        observation_covariance: The global observation noise covariance estimated from EM.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame with the original signal and added columns for filtered and smoothed results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for signal in processed_signals:\n",
    "        signal_copy = signal.copy()  # Preserve the original data\n",
    "        observations = signal_copy['depth'].values\n",
    "\n",
    "        # Initialize Kalman Filter with the global parameters\n",
    "        kf = KalmanFilter(\n",
    "            transition_matrices=transition_matrix,\n",
    "            observation_matrices=np.array([[1, 0, 0]]),  # Observation model\n",
    "            transition_covariance=process_noise_base,\n",
    "            observation_covariance=observation_covariance,\n",
    "            initial_state_mean=np.zeros(transition_matrix.shape[0]),\n",
    "            initial_state_covariance=np.eye(transition_matrix.shape[0])\n",
    "        )\n",
    "\n",
    "        # Apply filtering and smoothing\n",
    "        filtered_state_means, _ = kf.filter(observations)\n",
    "        smoothed_state_means, _ = kf.smooth(observations)\n",
    "\n",
    "        # Add filtered and smoothed results to the signal DataFrame\n",
    "        signal_copy['filtered_depth'] = filtered_state_means[:, 0]  # First state: depth\n",
    "        signal_copy['smoothed_depth'] = smoothed_state_means[:, 0]  # First state: depth\n",
    "        signal_copy['velocity'] = filtered_state_means[:, 1]  # Second state: velocity\n",
    "        signal_copy['acceleration'] = filtered_state_means[:, 2]  # Third state: acceleration\n",
    "\n",
    "        results.append(signal_copy)\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:23:18.507746Z",
     "start_time": "2024-12-06T05:23:18.412395Z"
    }
   },
   "id": "aabe3c6e0acca96e"
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [],
   "source": [
    "filtered_and_smoothed_signals = apply_kalman_filter(\n",
    "    df['processed_signal'], \n",
    "    transition_matrix, \n",
    "    process_noise_base, \n",
    "    observation_covariance\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:23:34.275742Z",
     "start_time": "2024-12-06T05:23:18.416035Z"
    }
   },
   "id": "21c09db023e3d60c"
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    time  depth  filtered_depth  smoothed_depth  velocity  acceleration\n",
      "0      0    0.0        0.000000      -14.222196  0.000000      0.000000\n",
      "1     60    0.0        0.000000       -5.869715  0.000000      0.000000\n",
      "2    120    0.0        0.000000        2.189674  0.000000      0.000000\n",
      "3    180    0.0        0.000000        9.922296  0.000000      0.000000\n",
      "4    240    0.0        0.000000       17.297464  0.000000      0.000000\n",
      "5    300   10.0        7.104479       24.287543  4.502586      0.477264\n",
      "6    740   15.0       13.741252       30.867991  6.655540      0.566013\n",
      "7    866   18.0       18.758472       37.017386  7.075441      0.481748\n",
      "8   1001   19.0       21.731063       42.717428  6.384731      0.338724\n",
      "9   1574   20.0       23.584270       47.952933  5.419709      0.213516\n",
      "10  2014   25.0       26.825993       52.711801  5.157691      0.155129\n",
      "11  2141   28.0       29.934264       56.984973  4.884700      0.107396\n",
      "12  2715   42.0       37.858592       60.766376  6.000095      0.126102\n",
      "13  3030   50.0       46.236137       64.052845  6.917507      0.127372\n",
      "14  3410   58.0       54.833901       66.844039  7.629284      0.115537\n",
      "15  4039   72.0       65.777780       69.142344  8.654342      0.109032\n",
      "16  4102   73.0       73.583134       70.952759  8.769009      0.073640\n",
      "17  4362   80.0       81.200585       72.282777  8.774370      0.037924\n",
      "18  4615   83.0       87.354588       73.142258  8.468823     -0.001120\n",
      "19  4804   85.0       92.125876       73.543285  7.943110     -0.039360\n",
      "20  5307   88.0       96.172980       73.500026  7.355604     -0.073260\n",
      "21  5433   88.0       98.839711       73.028573  6.627867     -0.103630\n",
      "22  5686   89.0      100.745365       72.146794  5.881922     -0.128846\n",
      "23  6000   89.0      101.827395       70.874167  5.119015     -0.149215\n",
      "24  6127   86.0      101.555810       69.231616  4.283556     -0.165087\n",
      "25  6190   86.0      100.959204       67.241347  3.516275     -0.176181\n",
      "26  6261   84.0       99.678075       64.926680  2.770257     -0.183170\n",
      "27  6324   84.0       98.308623       62.311879  2.108972     -0.186694\n",
      "28  6701   76.0       95.235918       59.421990  1.364165     -0.186308\n",
      "29  6891   71.0       91.421644       56.282672  0.647866     -0.182454\n",
      "30  6954   69.0       87.608338       52.920038  0.026347     -0.176156\n",
      "31  7018   68.0       84.003656       49.360491 -0.495061     -0.168225\n",
      "32  7081   65.0       80.241316       45.630574 -0.958216     -0.158713\n",
      "33  7529   50.0       74.354931       41.756817 -1.512762     -0.145136\n",
      "34  8788    3.0       61.588122       37.765594 -2.462376     -0.119954\n",
      "35  8848    0.0       50.027496       33.682981 -3.188635     -0.094489\n",
      "36  8908    0.0       39.970894       29.534626 -3.704342     -0.070095\n",
      "37  8968    0.0       31.214988       25.345624 -4.052421     -0.047153\n",
      "38  9028    0.0       23.587641       21.140399 -4.267148     -0.025879\n",
      "39  9088    0.0       16.942591       16.942591 -4.375981     -0.006379\n"
     ]
    }
   ],
   "source": [
    "print(filtered_and_smoothed_signals[5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:37:47.691821Z",
     "start_time": "2024-12-06T05:37:47.686694Z"
    }
   },
   "id": "b8727c5e70d027eb"
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [
    "df['filtered_and_smoothed_signal'] = filtered_and_smoothed_signals\n",
    "    # transition_matrix = initial_guess['transition_matrix']\n",
    "    # process_noise_cov = initial_guess['process_noise_cov']\n",
    "    # observation_matrix = initial_guess['observation_matrix']\n",
    "    # observation_noise_cov = initial_guess['observation_noise_cov']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:23:34.432479Z",
     "start_time": "2024-12-06T05:23:34.334513Z"
    }
   },
   "id": "8ef2c61333ed10a1"
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T05:23:34.437661Z",
     "start_time": "2024-12-06T05:23:34.397450Z"
    }
   },
   "id": "a26c19d250d2d6d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
